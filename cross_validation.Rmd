---
title: "Cross Validation"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)

library(modelr)
library(mgcv)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Simulate a dataset

```{r}
set.seed(1)

nonlin_df = 
  tibble(
    id = 1:100,
    x = runif(100, 0, 1),
    y = 1 - 10 * (x - .3) ^ 2 + rnorm(100, 0, .3)
  )

nonlin_df %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point()

```

Create splits by hand; fit some models.

```{r}
train_df = sample_n(nonlin_df, 80) ##80 observations ## 80-20 is common, want enough observations in the training data set so that you can fit the model well, but also want enough data points in the testing data set so the root mean squared error is about right. 

test_df = anti_join(nonlin_df, train_df, by = "id") ## find the people who are not overlapping in the two data sets

ggplot(train_df, aes(x = x, y = y)) + 
  geom_point() +
  geom_point(data = test_df, color = "red")
```

Fit my models:

```{r}
linear_mod = lm(y ~ x, data = train_df)
smooth_mod = mgcv::gam(y ~ s(x), data = train_df) ## y is a smooth function of x 
wiggly_mod = mgcv::gam(y ~ s(x, k = 30), sp = 10e-6, data = train_df)
```

Plot the results 

```{r}
train_df %>% 
  add_predictions(smooth_mod) %>% 
  ggplot(aes(x = x, y = y)) +
  geom_point() + 
  geom_line(aes(y = pred))

## nonlinear model
train_df %>% 
  add_predictions(wiggly_mod) %>% 
  ggplot(aes(x = x, y = y)) +
  geom_point() + 
  geom_line(aes(y = pred))

## linear is not complex enough
train_df %>% 
  add_predictions(linear_mod) %>% 
  ggplot(aes(x = x, y = y)) +
  geom_point() + 
  geom_line(aes(y = pred))
```

quantify the results

```{r}
rmse(linear_mod, test_df) ## take linear model, given the coefficient in the linear model, will create predicted value for the testing dataset and subtract those from the observed outcome, take the difference between those and add them up

rmse(smooth_mod, test_df)
rmse(wiggly_mod, test_df)

```

* Iteration process that goes back to the 80-20 and splits and run again and repeatedly 

## CV iteratively 

Use `modelr::crossv_mc`.

```{r}
## 100 training test splits, now what happen when I fit a model to the training set, what is the rmse when taking the model fit of the training set and apply to the testing set. GET RMSE

cv_df = 
  crossv_mc(nonlin_df, n = 100)

## Taking a quick look
cv_df %>% pull(train) %>%  .[[1]] %>% as_tibble()

## Make it into tibble
cv_df = 
  crossv_mc(nonlin_df, n = 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

```


Let's fit some models...

```{r}
cv_df = 
  cv_df %>% 
  mutate(
    linear_mod = map(.x = train, ~lm(y~x, data = .x)),
    smooth_mod = map(.x = train, ~gam(y~s(x), data = .x)),
    wiggly_mod = map(.x = train, ~gam(y ~ s(x, k = 30), sp = 10e-6, data = .x))
  ) %>% 
  mutate(
    rmse_linear = map2_dbl(.x = linear_mod, .y = test, ~rmse(model = .x, data = .y)),
    rmse_smooth = map2_dbl(.x = smooth_mod, .y = test, ~rmse(model = .x, data = .y)),
    rmse_wiggly = map2_dbl(.x = wiggly_mod, .y = test, ~rmse(model = .x, data = .y))
  ) 

## mapping over 2 things, will map cross the linear model column and the testing dataset, get rmse from linear model and apply to the testing dataset for all sample.   
```

Look at output

```{r}
cv_df %>% 
  select(.id, starts_with("rmse")) %>% 
  pivot_longer(
    rmse_linear:rmse_wiggly,
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_boxplot()
```


## Child Growth data

import data 

```{r}
child_growth_df = read_csv("nepalese_children.csv") %>% 
  mutate(
    weight_cp = (weight > 7) * (weight - 7)
  )
```

```{r}
child_growth_df %>% 
  ggplot(aes(x = weight, y = armc)) + 
  geom_point(alpha = 0.2)
```

consider candidate models.

```{r}
linear_mod = lm(armc ~ weight, data = child_growth_df)
pwl_mod = lm(armc ~ weight + weight_cp, data = child_growth_df)
smooth_mod = gam(armc ~ s(weight), data = child_growth_df)
```

```{r}
child_growth_df %>% 
  add_predictions(pwl_mod) %>% 
  ggplot(aes(x = weight, y = armc)) + 
  geom_point(alpha = 0.2) +
  geom_line(aes(y = pred), color = "red")
```

use cv to compare models. 

```{r}
cv_df = 
  crossv_mc(child_growth_df, n = 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )
```

Fit models and extract RMSE

```{r}
cv_df = 
  cv_df %>% 
  mutate(
    linear_mod = map(.x = train, ~lm(armc ~ weight, data = .x)),
    pwl_mod = map(.x = train, ~lm(armc ~ weight + weight_cp, data = .x)),
    smooth_mod = map(.x = train, ~gam(armc ~ s(weight), data = .x))
  ) %>% 
  mutate(
    rmse_linear = map2_dbl(.x = linear_mod, .y = test, ~rmse(model = .x, data = .y)),
    rmse_pwl = map2_dbl(.x = pwl_mod, .y = test, ~rmse(model = .x, data = .y)),
    rmse_smooth = map2_dbl(.x = smooth_mod, .y = test, ~rmse(model = .x, data = .y))
  ) 

```

Look at RMSE distribution

```{r}
cv_df %>% 
  select(.id, starts_with("rmse")) %>% 
  pivot_longer(
    rmse_linear:rmse_smooth,
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_boxplot()
```

* piece wise has nice interpretation 
* If 7 is the best change point, we can change the cp and compare different change points in cross validation. Choosing where the knot is cross validation

